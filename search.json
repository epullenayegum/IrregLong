[{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Analysis of longitudinal data with irregular observation times","text":"Longitudinal data often follow-times irregular potentially related outcomes. example, clinic-based cohort study follow-part usual care, patients may visit often unwell. risks -estimating burden disease unless data analysed appropriately. example, study HIV positive mothers, Buzkova et al Buzkova, Brown, John-Stewart (2010) found two-fold -estimation estimated prevalence pneumonia analysis ignored fact women likely visit scheduled visits unwell. two categories methods available analysing type data: methods based inverse-intensity weighting, methods based semi-parametric joint models (see Pullenayegum Lim (2016) overview). package provides methods inverse-intensity weighting. Inverse-intensity weighting weights data reciprocal intensity (, equivalently, hazard) visit process. Inverse-intensity weighting works similar way survey weighting: observations higher intensity -represented data, hence receive less weight. Conversely, observations lower intensity -represented data, hence receive weight. Lin, Scharfstein, Rosenheck (2004) show inverse-intensity weighting followed marginal analysis generalized estimating equation (GEE) results unbiased estimation, subject assumptions set . package contains functions compute inverse-intensity weights, also fit inverse-intensity weighted GEEs. Sometimes inference may desired model weighting straightforward, example generalized linear mixed model latent class mixed model. cases, multiple outputation useful alternative inverse-intensity weighting. Multiple outputation works discarding (outputting) excess data (Hoffman, Sen, Weinberg 2001; Follmann, Proschan, Leifer 2003). Visits randomly deleted dataset probability inversely proportional visit intensity (Pullenayegum 2016). resulting thinned visit process independent outcome process (subject assumptions ), can hence analysed using standard methods. avoid wasting data, random deletion repeated multiple times results analysis combined. Conceptually, multiple outputation opposite multiple imputation: multiple imputation imputes missing observations multiple times, multiple outputation discards excess observations multiple times. package contains functions create outputted datasets, well combine results across multiple outputations.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"review-of-inverse-intensity-weighted-gees","dir":"Articles","previous_headings":"","what":"Review of Inverse-intensity weighted GEEs","title":"Analysis of longitudinal data with irregular observation times","text":"Suppose \\(Y_i(t)\\) outcome interest subject \\(\\) time \\(t\\), let \\(X_i(t)\\) possibly time-dependent covariate, suppose interest marginal model \\[E(Y_i(t)|X_i(t))=X_i(t)\\beta.\\] Moreover, suppose observe \\(Y_i\\) times \\(T_{i1},T_{i2},\\ldots, T_{in_i}\\). Let \\(N_i(t)\\) counting process visit times, \\(N_i(t)=\\sum_{j}(T_{ij}\\leq t)\\), \\(()\\) indicator function. Suppose moreover vector observed covariates \\(Z_i(t)\\) \\[\\lim_{\\delta \\downarrow 0} \\frac{E(N(t)-N(t-\\delta))|Y_i(t),Z_i(t))}{\\delta}=\\frac{E(N(t)-N(t-\\delta))|Z_i(t))}{\\delta}=\\lambda(t;Z_i(t))\\] hazard function \\(\\lambda\\). assumption met, alternative methods analysis considered (e.g. semi-parametric joint models). usual GEE equations result biased estimates \\(\\beta\\) since \\[E(\\sum_i\\int_0^\\tau X_i^\\prime (Y_i(t) - X_i(t)\\beta)dN_i(t)) =E(\\sum_i\\int_0^\\tau X_i^\\prime E((Y_i(t) - X_i(t)\\beta)dN_i(t)\\mid X_i(t)) \\neq 0  \\] Provided conditional independence assumption holds, consistent estimates \\(\\beta\\) may obtained weighting GEE equations \\(sw_i(t)=s_0(t)/\\lambda_i(t)\\) \\[E(\\sum_i\\int_0^\\tau X_i^\\prime sw_i(t)(Y_i(t) - X_i(t)\\beta)dN_i(t)) =E(\\sum_i\\int_0^\\tau X_i^\\prime E(sw_i(t)(Y_i(t) - X_i(t)\\beta)dN_i(t)\\mid X_i(t),Y_i(t)) \\\\ = E(\\sum_i\\int_0^\\tau X_i^\\prime sw_i(t)(Y_i(t) - X_i(t)\\beta)\\lambda_i(t)dt=0.  \\]","code":""},{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"implementing-inverse-intensity-weighting","dir":"Articles","previous_headings":"","what":"Implementing Inverse-Intensity weighting","title":"Analysis of longitudinal data with irregular observation times","text":"first step inverse-intensity weighting calculate weights, usually fitting proportional hazards model recurrent event process formed visit times. , one fits model \\[\\lambda(t;Z_i(t))=\\lambda_0(t)\\exp(Z_i(t)\\gamma).\\] can done using coxph function, however data usually requires pre-processing. Firstly, counting process formulation takes form Surv(start.time,stop.time,event) typically requires time variable lagged. Time-varying covariates often need lagged well. Secondly, follow-stopped time later last visit, additional rows capturing censoring time must added dataset. example, follow-stopped two years, individual’s last visit 1.5 years, must include information visit 1.5 years two years estimating visit intensity model. Using data just observed visits ignores . IrregLong package simplifies modelling visit process creating dataset lagged variables (specified using lagvars=) time intervals corresponding censoring times (specified using maxfu=). inverse-intensity weight \\(w_i(t) = \\frac{\\exp(-Z_i(t)\\gamma)}{\\lambda_0(t)}\\). Following Buzkova Lumley (2007), inverse-intensity weights package stabilized baseline hazard \\(\\lambda_0(t)\\), stabilized weight \\(sw_i(t)=\\exp(-Z_i(t)\\gamma)\\). settings one may additionally wish stabilize function time-invariant covariates \\(X_i(t)\\), option included functions. One can fit GEE obtain regression coefficients \\(\\beta\\) corresponding regressing \\(Y_i(t)\\) \\(X_i(t)\\), weighting \\(sw_i(t)\\). important practical point using inverse-intensity weighting working variance GEE must set identity. functions fitting GEEs interpret weights indicating heteroscedasticity. Thus \\(Y_i\\) vector observations subject \\(\\), \\(X_i\\) matrix corresponding covariates, \\(R_i\\) working variance matrix \\(D_i\\) diagonal matrix whose \\(jj\\) entry weight \\(j^{th}\\) observation subject \\(\\), standard GEE software solves \\[\\sum_iX_i^\\prime D_i^{1/2}R_i^{-1}D_i^{1/2}(Y_i-X_i\\beta)=0,\\] whereas wish solve \\[\\sum_iX_i^\\prime R_i^{-1}D_i(Y_i-X_i\\beta)=0.\\] two , however, identical \\(R_i\\) identity matrix. first glance may seem appealing create GEE estimation function implements weights desired allow non-diagonal working variance matrices, note working variance variance \\(D_i(Y_i-X_i\\beta)\\) rather \\((Y_i-X_i\\beta)\\). Since weights usually involve time-dependent covariates often internal, standard correlation structures (exchangeable, autoregressive) become less plausible.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"example","dir":"Articles","previous_headings":"Implementing Inverse-Intensity weighting","what":"Example","title":"Analysis of longitudinal data with irregular observation times","text":"methods illustrated using Phenobarb dataset MEMSS package. Routine clinical pharmacokinetic data collected 59 preterm infants received phenobarbital order prevent seizures. Blood draws taken determine serum concentration phenobarbital, timing number draws varying among infants. purposes illustration analysis focuses pharmacokinetics mean serum concentration phenobarbital time. dataset contains rows corresponding times phenobarbital given others blood draw taken determine serum phenobarbital concentration. visit intensity model, event interest concentration measured, set variable event=1 concentration measured zero otherwise. data restricted time points concentration measurement taken. original pharmacokinetic analysis restricts attention first 16 days life, also . can helpful begin exploring extent visit irregularity. begin simple summary statistics number events per Subject, plot times measurement subjects.  shows median 3 visits per subject range 1 6. plot shows initial measurement shortly birth, observations times vary among subjects. extent irregularity can explored visit frequency plot. plot derived dividing time interval interest sets bins bin widths becoming increasingly wider across sets. set bins, mean proportion individuals 0, 1 >1 visit per bin calculated. plotted either number bins measure bin width. study protocol specify recommended visit times, sets bins can defined either intervals equal widths (different numbers bins set), intervals expected number visits per bin constant across bins (, varying numbers bins set). expected number visits bin simply area cumulative hazard bin. visit frequency plot shows mean proportion individuals 1 visit per bin highest 0.5 3 bins, clearly consistent repeated measures. Finally, area curve (AUC) proportion subjects \\(>1\\) visits per bin plotted proportion subjects \\(0\\) visits per bin can used numeric summary extent irregularity. perfect repeated measures, AUC 0; Poisson process, AUC 0.25. log transformed version AUC also available; version perfect repeated measures value zero Poisson process AUC 100. AUC example 0.18, transformed value 64, demonstrating high degree irregularity.  fit inverse intensity weighted GEE, one begins modelling visit intensity. Although IrregLong package includes function calculates inverse-intensity weights weighted GEE single command, can helpful start focussing visit intensity model. Modelling usually done Cox proportional hazards model recurrent visit process. , need specify time periods risk, need lag time variable. time-dependent covariates suspect value last measurement predictive next measurement taken, time-dependent covariates must also lagged. IrregLong package simplifies process allowing user specify covariates lagged (lagvars=c(“time”,“conc”)) creating lagged covariates internally (time.lag,conc.lag). value lagged variables default missing first observation subject, can changed lagfirst argument. set lagged value time first observed blood draw zero (lagfirst=0) since observation started birth infants. Similarly, set lagged value serum phenobarbital concentration zero first draw, since last known value serum concentration birth, prior administration phenobarbital, allow non-linear relationship concentration log visit intensity. Since Apgar score birthweight significant, consider whether model can simplified - first including Apgar score indicator (\\(\\geq 5\\) vs. \\(<5\\)), removing variables significant. thus appears last concentration predictive time next concentration measurement. established model visit intensity, now turn modelling serum concentration function time. plot concentration time shows relationship unlikely linear, even weighted data. thus use fractional polynomials model shape association time.  Fractional polynomials consider powers -2, -1, -0.5, 0.5, 1, 2, 3, log-transform, use best-fitting among . Since weighting tends lead dramatic changes shape relationship outcome covariates, use unweighted data choose functional form time, use adjusted R-squared measure goodness fit. Based , choose log transform time, now-consider whether second order fractional polynomial improve fit. involves adding, turn, powers previously considered, well \\(time\\times\\log(time)\\). thus use time^3 log(time) describe concentration time. also check best functional form weighted data: models, thus use time, time^3, log(time). inverse-intensity-weighted GEE can fitted using function iiwgee. function specifies first formula GEE, formula inverse intensity weights. Note iiwgee function include option working variance. discussed , working inverse-intensity weights, working variance always identity. iiwgee function returns inverse-intensity weighted GEE fit: comparison, also fit unweighted GEE, plot two serum concentration trajectories  iiwgee function also returns fitted visit intensity model:","code":"library(IrregLong) library(MEMSS) library(survival) library(geepack) library(data.table) data(Phenobarb) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) data <- data[data$time<16*24,] data <- data[order(data$id,data$time),] head(data) ##     Subject  Wt Apgar ApgarInd  time dose conc event id ## 2         1 1.4     7     >= 5   2.0   NA 17.3     1  1 ## 12        1 1.4     7     >= 5 112.5   NA 31.0     1  1 ## 136      10 1.4     7     >= 5   1.2   NA 19.9     1  2 ## 142      10 1.4     7     >= 5  70.7   NA 23.4     1  2 ## 149      10 1.4     7     >= 5 142.2   NA 30.9     1  2 ## 155      11 1.2     7     >= 5  57.5   NA 24.3     1  3 summary(tapply(data$event,data$Subject,sum)) ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  ##    1.00    2.00    3.00    2.61    3.00    6.00 abacus.plot(n=59,time=\"time\",id=\"Subject\",data=data,tmin=0,tmax=16*24,  xlab.abacus=\"Time in hours\",pch=16,col.abacus=gray(0.8)) counts <- extent.of.irregularity(data,time=\"time\",id=\"id\",    scheduledtimes=NULL, cutpoints=NULL,ncutpts=50,     maxfu=16*24, plot=TRUE,legendx=30,legendy=0.8,   formula=Surv(time.lag,time,event)~1,tau=16*24) counts$auc ## [1] 0.1814126 counts$transformed.auc ## [1] 65.02388 data$Apgar <- as.numeric(data$Apgar) i <- iiw.weights(Surv(time.lag,time,event)~Wt + Apgar +                     I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+       cluster(Subject),id=\"Subject\",time=\"time\",event=\"event\",data=data,       invariant=c(\"Subject\",\"Wt\",\"Apgar\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,       lagfirst=c(0,0),first=FALSE) i$m ## Call: ## coxph(formula = Surv(time.lag, time, event) ~ Wt + Apgar + I(conc.lag >  ##     0 & conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) +  ##     I(conc.lag > 30), data = datacox, cluster = Subject) ##  ##                                           coef exp(coef) se(coef) robust se ## Wt                                    -0.11227   0.89380  0.12403   0.11276 ## Apgar                                 -0.02280   0.97746  0.03541   0.03914 ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -2.24896   0.10551  0.32814   0.40854 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -2.66469   0.06962  0.33306   0.38537 ## I(conc.lag > 30)TRUE                  -2.98770   0.05040  0.42573   0.47461 ##                                            z        p ## Wt                                    -0.996    0.319 ## Apgar                                 -0.582    0.560 ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -5.505 3.69e-08 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -6.915 4.69e-12 ## I(conc.lag > 30)TRUE                  -6.295 3.07e-10 ##  ## Likelihood ratio test=71.26  on 5 df, p=5.589e-14 ## n= 213, number of events= 154 i <- iiw.weights(Surv(time.lag,time,event)~Wt + ApgarInd + I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+        cluster(Subject),id=\"Subject\",time=\"time\",event=\"event\",data=data,       invariant=c(\"Subject\",\"Wt\",\"ApgarInd\"),lagvars=c(\"time\",\"conc\"), maxfu=16*24,lagfirst=c(0,0),first=FALSE) i$m ## Call: ## coxph(formula = Surv(time.lag, time, event) ~ Wt + ApgarInd +  ##     I(conc.lag > 0 & conc.lag <= 20) + I(conc.lag > 20 & conc.lag <=  ##     30) + I(conc.lag > 30), data = datacox, cluster = Subject) ##  ##                                           coef exp(coef) se(coef) robust se ## Wt                                    -0.16625   0.84683  0.12404   0.12749 ## ApgarInd>= 5                           0.29125   1.33810  0.22949   0.34827 ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -2.35868   0.09455  0.34240   0.37226 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -2.75127   0.06385  0.34814   0.32775 ## I(conc.lag > 30)TRUE                  -3.11277   0.04448  0.44268   0.44155 ##                                            z        p ## Wt                                    -1.304    0.192 ## ApgarInd>= 5                           0.836    0.403 ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -6.336 2.36e-10 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -8.395  < 2e-16 ## I(conc.lag > 30)TRUE                  -7.050 1.79e-12 ##  ## Likelihood ratio test=72.57  on 5 df, p=2.994e-14 ## n= 213, number of events= 154 i <- iiw.weights(Surv(time.lag,time,event)~Wt + I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+        cluster(Subject),id=\"Subject\",time=\"time\",event=\"event\",data=data,       invariant=c(\"Subject\",\"Wt\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=c(0,0),first=FALSE) i$m ## Call: ## coxph(formula = Surv(time.lag, time, event) ~ Wt + I(conc.lag >  ##     0 & conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) +  ##     I(conc.lag > 30), data = datacox, cluster = Subject) ##  ##                                           coef exp(coef) se(coef) robust se ## Wt                                    -0.13679   0.87215  0.11897   0.11778 ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -2.26719   0.10360  0.32831   0.40747 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -2.66595   0.06953  0.33457   0.37910 ## I(conc.lag > 30)TRUE                  -2.99587   0.04999  0.42698   0.47295 ##                                            z        p ## Wt                                    -1.161    0.245 ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -5.564 2.63e-08 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -7.032 2.03e-12 ## I(conc.lag > 30)TRUE                  -6.334 2.38e-10 ##  ## Likelihood ratio test=70.86  on 4 df, p=1.496e-14 ## n= 213, number of events= 154 i <- iiw.weights(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30) +        cluster(Subject),id=\"Subject\",time=\"time\",event=\"event\",data=data,       invariant=c(\"Subject\",\"Wt\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=c(0,0),first=FALSE) i$m ## Call: ## coxph(formula = Surv(time.lag, time, event) ~ I(conc.lag > 0 &  ##     conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) + I(conc.lag >  ##     30), data = datacox, cluster = Subject) ##  ##                                           coef exp(coef) se(coef) robust se ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -2.27453   0.10284  0.33148   0.40497 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -2.67331   0.06902  0.33681   0.37398 ## I(conc.lag > 30)TRUE                  -2.99982   0.04980  0.42794   0.46762 ##                                            z        p ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -5.617 1.95e-08 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -7.148 8.79e-13 ## I(conc.lag > 30)TRUE                  -6.415 1.41e-10 ##  ## Likelihood ratio test=69.47  on 3 df, p=5.542e-15 ## n= 213, number of events= 154 plot(data$time,data$conc,xlim=c(0,200),pch=16, xlab=\"Time in hours\", ylab=\"Concentration\") rsq1 <- array(dim=8) rsq1[1] <- summary(lm(conc~time,data=data))$adj.r.squared rsq1[2] <- summary(lm(conc~I((time)^0.5),data=data))$adj.r.squared rsq1[3] <- summary(lm(conc~I((time)^2),data=data))$adj.r.squared rsq1[4] <- summary(lm(conc~I((time)^3),data=data))$adj.r.squared rsq1[5] <- summary(lm(conc~log(time),data=data))$adj.r.squared rsq1[6] <- summary(lm(conc~I((time)^(-0.5)),data=data))$adj.r.squared rsq1[7] <- summary(lm(conc~I((time)^(-1)),data=data))$adj.r.squared rsq1[8] <- summary(lm(conc~I((time)^(-2)),data=data))$adj.r.squared which.max(rsq1) ## [1] 5 rsq1[which.max(rsq1)] ## [1] 0.1952896 rsq2 <- array(dim=8) rsq2[1] <- summary(lm(conc~log(time)+ time,data=data))$adj.r.squared rsq2[2] <- summary(lm(conc~log(time)+ I((time)^0.5),data=data))$adj.r.squared rsq2[3] <- summary(lm(conc~log(time) + I((time)^2),data=data))$adj.r.squared rsq2[4] <- summary(lm(conc~log(time)+ I((time)^3),data=data))$adj.r.squared rsq2[5] <- summary(lm(conc~log(time)+ time:log(time),data=data))$adj.r.squared rsq2[6] <- summary(lm(conc~log(time) + I((time)^(-0.5))*log(1+time),data=data))$adj.r.squared rsq2[7] <- summary(lm(conc~log(time) + I((time)^(-1)),data=data))$adj.r.squared rsq2[8] <- summary(lm(conc~log(time)+ I((time)^(-2)),data=data))$adj.r.squared which.max(rsq2) ## [1] 4 rsq2[which.max(rsq2)] ## [1] 0.3468345 rsq1 <- array(dim=8) rsq1[1] <- summary(lm(conc~time,data=data,weight=i$iiw.weight))$adj.r.squared rsq1[2] <- summary(lm(conc~I((time)^0.5),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[3] <- summary(lm(conc~I((time)^2),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[4] <- summary(lm(conc~I((time)^3),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[5] <- summary(lm(conc~log(time),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[6] <- summary(lm(conc~I((time)^(-0.5)),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[7] <- summary(lm(conc~I((time)^(-1)),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[8] <- summary(lm(conc~I((time)^(-2)),data=data,weight=i$iiw.weight))$adj.r.squared which.max(rsq1) ## [1] 4 rsq1[which.max(rsq1)] ## [1] 0.163227 rsq1 <- array(dim=8) rsq1[1] <- summary(lm(conc~I((time)^3) +time,data=data,weight=i$iiw.weight))$adj.r.squared rsq1[2] <- summary(lm(conc~I((time)^3) +I((time)^0.5),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[3] <- summary(lm(conc~I((time)^3) +I((time)^2),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[4] <- summary(lm(conc~I((time)^3) + log(time):I(time^3),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[5] <- summary(lm(conc~I((time)^3) +log(time),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[6] <- summary(lm(conc~I((time)^3) +I((time)^(-0.5)),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[7] <- summary(lm(conc~I((time)^3) +I((time)^(-1)),data=data,weight=i$iiw.weight))$adj.r.squared rsq1[8] <- summary(lm(conc~I((time)^3) +I((time)^(-2)),data=data,weight=i$iiw.weight))$adj.r.squared which.max(rsq1) ## [1] 1 rsq1[which.max(rsq1)] ## [1] 0.3353907 iiwgee <- iiwgee(conc ~ time + I(time^3) + log(time),Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30) +cluster(id),         formulanull=NULL,id=\"id\",time=\"time\",event=\"event\",data=data,         invariant=c(\"id\",\"Wt\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=c(0,0),first=FALSE) summary(iiwgee$geefit) ##  ## Call: ## geeglm(formula = formulagee, family = family, data = data, weights = useweight,  ##     id = iddup, corstr = \"independence\") ##  ##  Coefficients: ##               Estimate    Std.err    Wald Pr(>|W|)     ## (Intercept)  1.912e+01  1.268e+00 227.512  < 2e-16 *** ## time         1.060e-01  2.571e-02  16.988 3.76e-05 *** ## I(time^3)   -1.469e-06  2.079e-07  49.917 1.60e-12 *** ## log(time)    7.501e-01  7.583e-01   0.978    0.323     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation structure = independence  ## Estimated Scale Parameters: ##  ##             Estimate Std.err ## (Intercept)    57.87   27.08 ## Number of clusters:   59  Maximum cluster size: 6 m <- geeglm(conc ~ time + I(time^3) + log(time) , id=Subject, data=data) time <- (2:200) unweighted <- cbind(rep(1,199),time,time^3,log(time))%*%m$coefficients weighted <- cbind(rep(1,199),time,time^3,log(time))%*%iiwgee$geefit$coefficients plot(data$time,data$conc,xlim=c(0,199),ylim=c(min(unweighted,weighted,data$conc),max(unweighted,weighted,data$conc)),pch=16,xlab=\"Time\",ylab=\"Serum phenobarbital concentration\") lines(time,unweighted,type=\"l\") lines(time,weighted,col=2) legend (0,60,legend=c(\"Unweighted\",\"Inverse-intensity weighted\"),col=1:2,bty=\"n\",lty=1) summary(iiwgee$phfit) ## Call: ## coxph(formula = Surv(time.lag, time, event) ~ I(conc.lag > 0 &  ##     conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) + I(conc.lag >  ##     30), data = datacox, cluster = id) ##  ##   n= 213, number of events= 154  ##  ##                                          coef exp(coef) se(coef) robust se ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -2.2745    0.1028   0.3315    0.4050 ## I(conc.lag > 20 & conc.lag <= 30)TRUE -2.6733    0.0690   0.3368    0.3740 ## I(conc.lag > 30)TRUE                  -2.9998    0.0498   0.4279    0.4676 ##                                           z Pr(>|z|)     ## I(conc.lag > 0 & conc.lag <= 20)TRUE  -5.62  1.9e-08 *** ## I(conc.lag > 20 & conc.lag <= 30)TRUE -7.15  8.8e-13 *** ## I(conc.lag > 30)TRUE                  -6.42  1.4e-10 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ##                                       exp(coef) exp(-coef) lower .95 upper .95 ## I(conc.lag > 0 & conc.lag <= 20)TRUE     0.1028       9.72    0.0465     0.227 ## I(conc.lag > 20 & conc.lag <= 30)TRUE    0.0690      14.49    0.0332     0.144 ## I(conc.lag > 30)TRUE                     0.0498      20.08    0.0199     0.125 ##  ## Concordance= 0.624  (se = 0.014 ) ## Likelihood ratio test= 69.5  on 3 df,   p=6e-15 ## Wald test            = 54.4  on 3 df,   p=9e-12 ## Score (logrank) test = 69.1  on 3 df,   p=7e-15,   Robust = 56.1  p=4e-12 ##  ##   (Note: the likelihood ratio and score tests assume independence of ##      observations within a cluster, the Wald and robust score tests do not)."},{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"multiple-outputation","dir":"Articles","previous_headings":"","what":"Multiple Outputation","title":"Analysis of longitudinal data with irregular observation times","text":"inverse-intensity weights calculated, alternative use perform multiple outputation. weights large, can result small outputted datasets, can helpful truncate weights. Moreover, smaller sample size outputted dataset results collinearity including three functions time, analysis use time time^3 , best fit weighted data. code computes 20 outputted datasets, analyses using unweighted GEE, combines results. multiple outputation estimates regression coefficients ($est), mean across outputations GEE estimates. multiple outputation standard error ($se) function within outputation standard errors outputation variance. relative efficiency using 20 outputations place possible outputations given RE.MO. example number observations per subject becomes small outputation, resulting usual sandwich variance estimator GEE underestimating standard error. reason, use small sample sandwich variance correction “geesmv” package. number options available, example used Mancl deRouen correction (Mancl DeRouen 2001). multiple outputation estimates based seed 16.0 (SE 1.53), -7.72e-07 (SE 1.16e-07) 3.42 (SE 5.52) intercept, \\(time\\), \\(time^3\\) respectively. relative efficiencies 1.01, 1.008, 1.008, suggesting little gained running outputations. Multiple outputation helpful analyses weighting difficult implement. One example semi-parametric joint model. Semi-parametric joint models useful latent variables influence outcome visit processes. consider Liang (Liang, Lu, Ying 2009) semi-parametric joint model: \\[Y_i(t)=\\beta_0(t) + X_i(t)\\beta + W_i(t)\\nu_{i1} + \\epsilon_i(t) \\] \\[\\lambda_i(t)=\\nu_{i2}\\lambda_0(t)\\exp(U_i\\gamma) \\] \\(W_i(t)\\) subset covariates \\(X_i(t)\\), \\(U_i\\) vector baseline covariates, \\(\\epsilon_i(t)\\) mean-zero random error, \\(\\nu_{i1}\\), \\(\\nu_{i2}\\) (potentially correlated) random effects. Liang model requires covariates model visits time invariant. practice, \\[\\lambda_i(t)=\\nu_{i2}\\lambda_0(t)\\exp(Z_i(t)\\gamma), \\] observed vector time-dependent auxiliary covariates \\(Z_i(t)\\) may reasonable. Multiple outputation makes inference model possible creating outputted datasets visit process depend observed covariates \\(Z_i(t)\\). datasets can analysed using Liang’s method special case covariates visit process model.","code":"library(geesmv)   reg <- function(data){   est <- summary(geeglm(conc~time + I(time^3), id=id,data=data))$coefficients[,1:2]   if(max(table(data$id))>1) est[,2] <- GEE.var.md(conc~time + I(time^3) , id=id,data=data)$cov.beta   est <- data.matrix(est)   return(est) } set.seed(301031) wt <- i$iiw.weight wt[wt>quantile(i$iiw.weight,0.95)] <- quantile(i$iiw.weight,0.95) m.mogee <- mo(20,reg,data,wt, singleobs=FALSE,id=\"id\",time=\"time\",keep.first=FALSE,var=TRUE) m.mogee"},{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"example-1","dir":"Articles","previous_headings":"Multiple Outputation","what":"Example","title":"Analysis of longitudinal data with irregular observation times","text":"consider example , now examining whether concentration differs Apgar score <5 birth score >=5, allowing random intercept potentially correlated frailty variable visit process. , take \\[conc_i(t)=\\beta_0(t) + \\beta_1I(Apgar_i<5) + \\beta_2I(Apgar\\geq 5)t + \\beta_3I(Apgar\\geq 5)t^3 +  \\nu_{i1} + \\epsilon_i(t),\\] visit process model given \\[\\lambda_i(t)=\\nu_{i2}\\lambda_0(t)\\exp((0<conc_i(T_{iN_i(t^-)})\\leq 20)\\gamma_1 + (20< conc_i(T_{iN_i(t^-)})\\leq 30)\\gamma_2 +\\\\ (conc_i(T_{iN_i(t^-)})> 30)\\gamma_3, \\] \\(\\nu_{i1}=(\\nu_{i11},\\nu_{i12})^\\prime\\) \\(\\nu_{i2}\\) potentially correlated \\(E(\\nu_{i1}\\mid\\nu_{i2})=\\theta(\\nu_{i2}-1)\\) \\(\\theta\\). Note calculating weights used outputation, frailty=TRUE option used visit intensity calculation lagged concentration internal covariate potentially correlated frailty variable, Cox model non-collapsible. analysis, time transformed days rather hours avoid computational problems Liang function. first three coefficients represent Apgar score, interaction time, interaction time^3 respectively, fourth coefficient estimated value \\(\\theta\\) final entry estimated variance frailty variable visit process model. Since case estimated frailty zero, can conclude Liang model needed.","code":"Liangmo <- function(data,Yname,Xnames,Wnames,maxfu,baseline){  x <- Liang(data=data,Yname=Yname,Xnames=Xnames,Wnames=Wnames,id=\"id\",time=\"time\",             maxfu=maxfu,baseline=baseline,Xfn=Xfn,Wfn=Wfn); print(x); return(x) } Xfn <- function(id,time){   # Group is time invariant so just use the first value for each subject   return(as.numeric(data$ApgarInd[data$id==id][1])) } Wfn <- function(id,time){   return(c(1,time)) } data$Intercept <- 1 data$time3 <- (data$time)^3 data$logtime <- log(data$time) data$ApgarInd.time <- as.numeric(data$ApgarInd)*data$time/24 data$ApgarInd.time3 <- as.numeric(data$ApgarInd)*((data$time/24)^3)  set.seed(301031) ifrailty <- iiw.weights(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)                          +frailty(id),id=\"id\",time=\"time\",event=\"event\",data=data,                            invariant=c(\"id\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,                       lagfirst=c(0,0), first=FALSE)  wt <- ifrailty$iiw.weight  m.moLiang <- mo(20,Liangmo,data,wt,           singleobs=FALSE,id=\"id\",time=\"time\",keep.first=FALSE,var=FALSE,Yname=\"conc\",          Xnames=c(\"ApgarInd\",\"ApgarInd.time\",\"ApgarInd.time3\"),           Wnames=c(\"Intercept\"),maxfu=16*24,baseline=0)  m.moLiang$est m.moLiang$est ## [1] -20.15766   5.25885  -0.02689        NA   0.00000"},{"path":"https://epullenayegum.github.io/IrregLong/articles/Irreglong-vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Analysis of longitudinal data with irregular observation times","text":"Buzkova, P., E. R. Brown, G. C. John-Stewart. 2010. “Longitudinal Data Analysis Generalized Linear Models Participant-Driven Informative Follow-: Application Maternal Health Epidemiology.” American Journal Epidemiology 171: 189–97. Buzkova, P., T. Lumley. 2007. “Longitudinal Data Analysis Generalized Linear Models Follow-Dependent Outcome-Related Variables.” Canadian Journal Statistics 35: 485–500. Follmann, D., M. Proschan, E. Leifer. 2003. “Multiple Outputation: Inference Complex Clustered Data Averaging Analyses Independent Data.” Biometrics 59: 420–29. Hoffman, E. B., P. K. Sen, C. Weinberg. 2001. “Within-Cluster Resampling.” Biometrika 88: 1121–34. Liang, Y., W. Lu, Z. Ying. 2009. “Joint Modeling Analysis Longitudinal Data Informative Observation Times.” Biometrics 65: 377–84. Lin, H., D. O. Scharfstein, R. . Rosenheck. 2004. “Analysis Longitudinal Data Irregular, Outcome-Dependent Follow-.” Journal Royal Statistical Society, Series B 66: 791–813. Mancl, LA, TA DeRouen. 2001. “Covariance Estimator Gee Improved Small-Sample Properties.” Journal Article. Biometrics 57 (1): 126–34. https://doi.org/10.1111/j.0006-341X.2001.00126.x. Pullenayegum, E. M. 2016. “Multiple Outputation Analysis Longitudinal Data Subject Irregular Observation.” Statistics Medicine 35: 1800–1818. Pullenayegum, E. M., L. S. H. Lim. 2016. “Longitudinal Data Subject Irregular Observation: Review Methods Focus Visit Processes, Assumptions, Study Design.” Statistical Methods Medical Research 25: 2992–3014.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Eleanor Pullenayegum. Maintainer.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pullenayegum E (2022). IrregLong: Analysis Longitudinal Data Irregular Observation Times. R package version 0.3.4, https://epullenayegum.github.io/IrregLong/.","code":"@Manual{,   title = {IrregLong: Analysis of Longitudinal Data with Irregular Observation Times},   author = {Eleanor Pullenayegum},   year = {2022},   note = {R package version 0.3.4},   url = {https://epullenayegum.github.io/IrregLong/}, }"},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"irreglong","dir":"","previous_headings":"","what":"R package IrregLong for analysing longitudinal data with irregular observation times","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"goal IrregLong package provide functions handling longitudinal data subject irregular observation.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"why-might-you-need-this-package","dir":"","previous_headings":"","what":"Why might you need this package?","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"longitudinal data assessment times vary among subjects, need ask vary, whether time assessment times associated outcome, appropriate method analysis . example, suppose estimating rate growth among newborns data collected part usual care. Typically, weight length measured every clinical encounter, include birth 2-month vaccinations. However, newborns slow regain birthweight seen frequently. Consequently, observations coresponding newborns growing slowly -represented data, lead -estimation rate growth unless account informative nature visit process. IrregLong package help assess irregular assessment times , whether measured predictors assessment times, analyse data accounting irregularity.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"can install development version IrregLong Github:","code":"devtools::install_github(\"epullenayegum/Irreglong/Irreglong\")"},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"examining-the-extent-of-irregularity","dir":"","previous_headings":"","what":"Examining the extent of irregularity","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"fitting models, wise examine extent irregularity data. many cases, sensible question ``closely data resemble repeated measures data?’’ quick visual way answering question abacus plot:","code":"abacus.plot(n=59,time=\"time\",id=\"Subject\",data=data,tmin=0,tmax=16*24,  xlab.abacus=\"Time in hours\",pch=16,col.abacus=gray(0.8))"},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"is-the-irregularity-informative","dir":"","previous_headings":"","what":"Is the irregularity informative?","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"decide extent irregularity sufficient warrant considering irregularity analysis, next question consider whether irregularity informative. Irregularity purely random (termed “Assessment Completely Random”, ACAR) need accounted , whereas irregularity associated outcome interest considered analysis. Irregularity results assessment process conditionally independent outcome given time conditionally previously observed data (termed “Assessment Random”, AAR) can handled inverse-intensity weighting. Irregularity results assessment process dependent outcome given time (termed “Assessment Random”, ANAR) best handled sensitivity analysis, methods currently developed. Specific cases ANAR, assessment outcome processes conditionally independent given random effects, can handled semi-parametric joint models. Given specific assumptions possible nature AAR, possible examine whether evidence ACAR. commonly, analyst specifies proportional intensity model assessment times given previously observed covariates; intensity rate ratios differ 1 provide evidence ACAR. function iiw.weights can help model assessment intensity, assuming proportional rates model. example uses data Phenobarb dataset MEMSS packageand shows serum concentration phenobarbital last assessment associated subsequent assessment intensity, suggesting ACAR assumption tenable.","code":"i <- iiw.weights(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30) +        cluster(Subject),id=\"Subject\",time=\"time\",event=\"event\",data=data,       invariant=c(\"Subject\",\"Wt\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=c(0,0),first=FALSE) i$m #> Call: #> coxph(formula = Surv(time.lag, time, event) ~ I(conc.lag > 0 &  #>     conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) + I(conc.lag >  #>     30), data = datacox, cluster = Subject) #>  #>                                           coef exp(coef) se(coef) robust se #> I(conc.lag > 0 & conc.lag <= 20)TRUE  -2.27453   0.10284  0.33148   0.40497 #> I(conc.lag > 20 & conc.lag <= 30)TRUE -2.67331   0.06902  0.33681   0.37398 #> I(conc.lag > 30)TRUE                  -2.99982   0.04980  0.42794   0.46762 #>                                            z        p #> I(conc.lag > 0 & conc.lag <= 20)TRUE  -5.617 1.95e-08 #> I(conc.lag > 20 & conc.lag <= 30)TRUE -7.148 8.79e-13 #> I(conc.lag > 30)TRUE                  -6.415 1.41e-10 #>  #> Likelihood ratio test=69.47  on 3 df, p=5.542e-15 #> n= 213, number of events= 154"},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"accounting-for-irregularity-when-assuming-assessment-at-random","dir":"","previous_headings":"","what":"Accounting for irregularity when assuming Assessment At Random","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"Inverse-intensity weighted GEEs popular way account AAR. can fitted using iiwgee function","code":"iiwgee <- iiwgee(conc ~ time + I(time^3) + log(time),Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) +                  I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30) +cluster(id),         formulanull=NULL,id=\"id\",time=\"time\",event=\"event\",data=data,         invariant=c(\"id\",\"Wt\"),lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=c(0,0),first=FALSE) summary(iiwgee$geefit) #>  #> Call: #> geeglm(formula = formulagee, family = family, data = data, weights = useweight,  #>     id = iddup, corstr = \"independence\") #>  #>  Coefficients: #>               Estimate    Std.err    Wald Pr(>|W|)     #> (Intercept)  1.912e+01  1.268e+00 227.512  < 2e-16 *** #> time         1.060e-01  2.571e-02  16.988 3.76e-05 *** #> I(time^3)   -1.469e-06  2.079e-07  49.917 1.60e-12 *** #> log(time)    7.501e-01  7.583e-01   0.978    0.323     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Correlation structure = independence  #> Estimated Scale Parameters: #>  #>             Estimate Std.err #> (Intercept)    57.87   27.08 #> Number of clusters:   59  Maximum cluster size: 6"},{"path":"https://epullenayegum.github.io/IrregLong/index.html","id":"alternative-approaches","dir":"","previous_headings":"","what":"Alternative approaches","title":"R package IrregLong for analysing longitudinal data with irregular observation times","text":"Multiple outputation similar weighting; “outputted” dataset observations selected probability inversely proportional observation intensity. Multiple outputation thus particularly useful want implement analytic model permit weighting (example, GLMM). package include functions outputation mo implementing multiple outputation. want assume specific case ANAR arises assessment outcome processes conditionally independent given random effects, semi-parametric joint models can used. IrregLong package includes function fitting Liang semi-parametric joint model.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a semi-parametric joint model — Liang","title":"Fit a semi-parametric joint model — Liang","text":"Fits semi-parametric joint model described Liang et al. (2009).","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a semi-parametric joint model — Liang","text":"","code":"Liang(   data,   Yname,   Xnames,   Wnames,   Znames = NULL,   formulaobs = NULL,   id,   time,   invariant = NULL,   lagvars = NULL,   lagfirst = NULL,   maxfu,   baseline,   Xfn = NULL,   Wfn = NULL,   ... )"},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a semi-parametric joint model — Liang","text":"data data frame containing variables model Yname character string indicating column containing outcome variable Xnames vector character strings indicating names columns fixed effects outcome regression model Wnames vector character strings indicating names columns random effects outcome regression model Znames vector character strings indicating names columns covariates visit intensity model formulaobs formula observation intensity model id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred invariant vector variable names corresponding variables data time-invariant. necessary list every variable, just invariant also included visit intensity model lagvars vector variable names corresponding variables need lagged one visit fit visit intensity model. Typically time one variables. function internally add columns data containing values lagged variables previous visit. Values lagged variables subject's first visit set NA. access variables specifying proportional hazards formulae, add \".lag\" variable wish lag. example, time variable time, time.lag time previous visit lagfirst vector giving value lagged variable first time within subject. helpful , example, time variable lagged know subjects entered study time zero maxfu maximum follow-time per subject. subjects follow-time, can supplied single number. Otherwise, maxfu dataframe first column specifying subject identifiers second giving follow-time subject. baseline indicator whether baseline (time=0) measurements included design. Equal 1 yes, 0 . Xfn function takes first argument subject identifier time second argument, returns value X specified subject specified time. Wfn function takes first argument subject identifier time second argument, returns value W specified subject specified time ... arguments Xfn Yfn","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a semi-parametric joint model — Liang","text":"regression coefficients corresponding fixed effects outcome regression model.  Closed form expressions standard errors regression coefficients available, Liang et al (2009) recommend obtaining bootstrapping.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a semi-parametric joint model — Liang","text":"function fits semi-parametric joint model described Liang (2009), using frailty model estimate parameters visit intensity model Liang method requires value X W every time observation period. Xfn left NULL, Liang function use, subject time t, values X W observation time closest t.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a semi-parametric joint model — Liang","text":"Liang Y, Lu W, Ying Z. Joint modelling analysis longitudinal data informative observation times. Biometrics 2009; 65:377-384.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/Liang.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a semi-parametric joint model — Liang","text":"","code":"# replicate simulation in Liang et al. if (FALSE) { library(data.table) library(survival) datasimi <- function(id){ X1 <- runif(1,0,1) X2 <- rbinom(1,1,0.5) Z <- rgamma(1,1,1) Z1 <- rnorm(1,Z-1,1) gamma <- c(0.5,-0.5) beta <- c(1,-1) hazard <- Z*exp(X1/2 - X2/2) C <- runif(1,0,5.8) t <- 0 tlast <- t y <- t + X1-X2 + Z1*X2 + rnorm(1,0,1) wait <- rexp(1,hazard) while(tlast+wait<C){   tnew <- tlast+wait     y <- c(y,tnew + X1-X2 + Z1*X2 + rnorm(1,0,1))     t <- c(t,tnew)     tlast <- tnew     wait <- rexp(1,hazard)  }  datai <- list(id=rep(id,length(t)),t=t,y=y,       X1=rep(X1,length(t)),X2=rep(X2,length(t)),C=rep(C,length(t)))  return(datai)  }  sim1 <- function(it,nsubj){  data <- lapply(1:nsubj,datasimi)  data <- as.data.frame(rbindlist(data))  data$event <- 1  C <- tapply(data$C,data$id,mean)  tapply(data$C,data$id,sd)  maxfu <- cbind(1:nsubj,C)  maxfu <- as.data.frame(maxfu)  res <- Liang(data=data, id=\"id\",time=\"t\",Yname=\"y\",             Xnames=c(\"X1\",\"X2\"),             Wnames=c(\"X2\"),Znames=c(\"X1\",\"X2\"), formulaobs=Surv(t.lag,t,event)~X1             + X2+ frailty(id),invariant=c             (\"id\",\"X1\",\"X2\"),lagvars=\"t\",lagfirst=NA,maxfu=maxfu,             baseline=1)  return(res)  }  # change n to 500 to replicate results of Liang et al.  n <- 10  s <- lapply(1:n,sim1,nsubj=200)  smat <- matrix(unlist(s),byrow=TRUE,ncol=4)  apply(smat,2,mean)  }"},{"path":"https://epullenayegum.github.io/IrregLong/reference/abacus.plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","title":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","text":"Create abacus plot Creates abacus plot, depicting visits per subject time","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/abacus.plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","text":"","code":"abacus.plot(   n,   time,   id,   data,   tmin,   tmax,   xlab.abacus = \"Time\",   ylab.abacus = \"Subject\",   pch.abacus = 16,   col.abacus = 1 )"},{"path":"https://epullenayegum.github.io/IrregLong/reference/abacus.plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","text":"n number subjects randomly sample. Subjects sampled without replacement therefore n must smaller total number subjects dataset time character string indicating column data contains time visit occurred id character string indicating column data identifies subjects data data frame containing variables model tmin smallest time include x-axis tmax largest time include x-axis xlab.abacus label x-axis ylab.abacus label y-axis pch.abacus plotting character points abacus plot col.abacus colour rails abacus plot","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/abacus.plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","text":"produces plot depicting observation times subject. values returned","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/abacus.plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","text":"function creates plot n randomly sampled individuals supplied dataset, one row per subject one point per visit. can useful visualising extent irregularity visit process. example, perfect repeated measures data (.e., irregularity), points line vertically. greater irregularity, points randomly scattered time.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/abacus.plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an abacus plot\nCreates an abacus plot, depicting visits per subject over time — abacus.plot","text":"","code":"library(MEMSS) #> Loading required package: lme4 #> Loading required package: Matrix #>  #> Attaching package: ‘MEMSS’ #> The following objects are masked from ‘package:datasets’: #>  #>     CO2, Orange, Theoph data(Phenobarb) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb[Phenobarb$event==1,] abacus.plot(n=20,time=\"time\",id=\"Subject\",data=data,tmin=0,tmax=16*24, xlab.abacus=\"Time in hours\",pch=16,col.abacus=gray(0.8))"},{"path":"https://epullenayegum.github.io/IrregLong/reference/addcensoredrows.html","id":null,"dir":"Reference","previous_headings":"","what":"Add rows corresponding to censoring times to a longitudinal dataset — addcensoredrows","title":"Add rows corresponding to censoring times to a longitudinal dataset — addcensoredrows","text":"Add rows corresponding censoring times longitudinal dataset","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/addcensoredrows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add rows corresponding to censoring times to a longitudinal dataset — addcensoredrows","text":"","code":"addcensoredrows(data, maxfu, tinvarcols, id, time, event)"},{"path":"https://epullenayegum.github.io/IrregLong/reference/addcensoredrows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add rows corresponding to censoring times to a longitudinal dataset — addcensoredrows","text":"data dataset rows added. data one row per observation maxfu maximum follow-time per subject. subjects follow-time, can supplied single number. Otherwise, maxfu dataframe first column specifying subject identifiers second giving follow-time subject. tinvarcols vector column numbers corresponding variables data time-invariant. id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred event character string indicating column data indicates whether visit occurred. every row corresponds visit, column consist entirely ones","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/addcensoredrows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add rows corresponding to censoring times to a longitudinal dataset — addcensoredrows","text":"original dataset extra rows corresponding censoring times","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/addcensoredrows.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add rows corresponding to censoring times to a longitudinal dataset — addcensoredrows","text":"","code":"x <- c(1:3,1:2,1:5) x0 <- c(rep(2,3),rep(0,2),rep(1,5)) id <- c(rep(1,3),rep(2,2),rep(3,5)) time <- c(0,4,6,2,3,1,3,5,6,7) event <- c(1,1,1,0,1,0,1,1,1,1) data <- as.data.frame(cbind(x,id,time,event,x0)) addcensoredrows(data,maxfu=8,id=\"id\",time=\"time\",tinvarcols=5,event=\"event\") #>     x id time event x0 #> 1   1  1    0     1  2 #> 2   2  1    4     1  2 #> 3   3  1    6     1  2 #> 11 NA  1    8     0  2 #> 4   1  2    2     0  0 #> 5   2  2    3     1  0 #> 12 NA  2    8     0  0 #> 6   1  3    1     0  1 #> 7   2  3    3     1  1 #> 8   3  3    5     1  1 #> 9   4  3    6     1  1 #> 10  5  3    7     1  1 #> 13 NA  3    8     0  1   x <- c(1:3,1:2,1:5) x0 <- c(rep(2,3),rep(0,2),rep(1,5)) id <- c(rep(1,3),rep(2,2),rep(3,5)) time <- c(0,4,6,2,3,1,3,5,6,7) event <- c(1,1,1,0,1,0,1,1,1,1) data <- as.data.frame(cbind(x,id,time,event,x0)) maxfu.id <- 1:3 maxfu.time <- c(6,5,8) maxfu <- cbind(maxfu.id,maxfu.time) maxfu <- as.data.frame(maxfu) addcensoredrows(data,maxfu=maxfu,id=\"id\",time=\"time\",tinvarcols=5,event=\"event\") #>     x id time event x0 #> 1   1  1    0     1  2 #> 2   2  1    4     1  2 #> 3   3  1    6     1  2 #> 4   1  2    2     0  0 #> 5   2  2    3     1  0 #> 11 NA  2    5     0  0 #> 6   1  3    1     0  1 #> 7   2  3    3     1  1 #> 8   3  3    5     1  1 #> 9   4  3    6     1  1 #> 10  5  3    7     1  1 #> 12 NA  3    8     0  1"},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":null,"dir":"Reference","previous_headings":"","what":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"Measures extent visit irregularity Provides visual numeric measures extent irregularity observation times longitudinal dataset","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"","code":"extent.of.irregularity(   data,   time = \"time\",   id = \"id\",   scheduledtimes = NULL,   cutpoints = NULL,   ncutpts = NULL,   maxfu = NULL,   plot = FALSE,   legendx = NULL,   legendy = NULL,   formula = NULL,   tau = NULL,   tmin = NULL )"},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"data data containing information subject identifiers visit times time character indicating column data contains times observations data made id character indicating column data contains subject identifiers. ids assumed consecutive integers, first subject id 1 scheduledtimes studies protocol-specified visit times, vector times. Defaults NULL, case assumed protocolized visit times cutpoints studies scheduled visit times, array dimension ncutpts length(scheduledtimes) 2 giving, ncutpts sets left right cutpoints protocolized scheduled visit times. left-hand cutpoints correspond cutpoints[,,1] right-hand cutpoints cutpoints[,,2]. Defaults NULL, case cutpoints computed described . ncutpts number sets cutpoints consider maxfu maximum follow-time per subject. subjects follow-time, can supplied single number. Otherwise, maxfu dataframe first column specifying subject identifiers second giving follow-time subject. plot logical parameter indicating whether plots produced. legendx x-coordinate position legend plot mean proportion individuals 0, 1 $>$ 1 visit per bin. legendy y-coordinate position legend plot mean proportion individuals 0, 1 $>$ 1 visit per bin. formula studies without protocolized visit times, formula null counting process model visit times. tau maximum time interest tmin minimum time considered constructing cutpoints bins placed symmetrically around scheduled observation times.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"list counts equal 3-dimensional ncutpts matrix giving, set cutpoints, mean proportion individuals zero, 1 >1 visits per bin, AUC, area curve plot proportion individuals >1 visit per bin vs. proportion individuals 0 visits per bin. transformed AUC (equal 100(1-log(4*(0.2-auc))/log(2))) also returned easier interpretation; transformed auc equal zero represents repeated measures, transformed auc assessment times occurring Poisson process value 100.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"function provides plots numerical summary extent irregularity visit times. given set cutpoints, computes proportion individuals 0, 1 >1 observation(s) bin, takes mean bins. sizes bins varied proportions plotted bin size. addition, mean proportion individuals >1 visit per bin plotted vs. mean proportion individuals 0 visits per bin, area curve calculated (AUC). AUC 0 represents perfect repeated measures Poisson Process AUC 0. cutpoints supplied, computed follows: () studies protocolized visit times, left- right-hand cutpoints positioned protocolized time minus (plus, right-hand cutpoints) (1,...,ncutpts)/ncutpts times gap previous (next, respectively) protocolized visit time; (b) studies protocolized visit times, cutpoints calculated finding, j 1,...,ncutpts largest times cumulative hazard less j divided cumulative hazard evaluated maximum time interest. corresponds choosing cutpoints expected number visits per bin roughly equal within set.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"Lokku , Birken CS, Maguire JL, Pullenayegum EM. Quantifying extent visit irregularity longitudinal data. International Journal Biostatistics 2021; Biometrika 2001; pp. 20200144 Lokku , Lim LS, Birken CS, Pullenayegum EM. Summarizing extent visit irregularity longitudinal data. BMC medical research methodology 2020; Vol.20 (1), p.135-135","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/extent.of.irregularity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measures of extent of visit irregularity\nProvides visual and numeric measures of the extent of irregularity in observation times in a longitudinal dataset — extent.of.irregularity","text":"","code":"if (FALSE) { # time-consuming so not run in R package build library(nlme) library(survival) data(Phenobarb) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) counts <- extent.of.irregularity(data,time=\"time\",id=\"id\",scheduledtimes=NULL, cutpoints=NULL,ncutpts=10, maxfu=16*24,plot=TRUE,legendx=NULL,legendy=NULL, formula=Surv(time.lag,time,event)~1,tau=16*24) counts$counts counts$auc }"},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a proportional hazards model for visit intensities, compute inverse-intensity weights. — iiw","title":"Given a proportional hazards model for visit intensities, compute inverse-intensity weights. — iiw","text":"longitudinal dataset subject irregular observation, use Cox proportional hazards model visit intensities compute inverse intensity weights","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a proportional hazards model for visit intensities, compute inverse-intensity weights. — iiw","text":"","code":"iiw(phfit, data, id, time, first)"},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given a proportional hazards model for visit intensities, compute inverse-intensity weights. — iiw","text":"phfit coxph object visit process data dataset featuring longitudinal data subject irregular observation inverse-intensity weights desired id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred first logical variable. TRUE, first observation individual assigned intensity 1. appropriate first visit baseline visit recruitment study occurred; case baseline visit observed probability 1.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Given a proportional hazards model for visit intensities, compute inverse-intensity weights. — iiw","text":"vector inverse-intensity weights row dataset. first observation subject assumed intensity 1.","code":""},{"path":[]},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Given a proportional hazards model for visit intensities, compute inverse-intensity weights. — iiw","text":"","code":"library(nlme) #>  #> Attaching package: ‘nlme’ #> The following object is masked _by_ ‘.GlobalEnv’: #>  #>     Phenobarb #> The following objects are masked from ‘package:MEMSS’: #>  #>     Alfalfa, Assay, BodyWeight, Cefamandole, Dialyzer, Earthquake, #>     Fatigue, Gasoline, Glucose, Glucose2, Gun, IGF, Machines, #>     MathAchieve, Meat, Milk, Muscle, Nitrendipene, Oats, Orthodont, #>     Ovary, Oxide, PBG, Phenobarb, Pixel, Quinidine, Rail, RatPupWeight, #>     Relaxin, Remifentanil, Soybean, Spruce, Tetracycline1, #>     Tetracycline2, Wafer, Wheat, Wheat2, ergoStool #> The following object is masked from ‘package:lme4’: #>  #>     lmList library(survival) library(geepack) library(data.table) data(Phenobarb) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) data <- data[data$time<16*24,] data <- lagfn(data, lagvars=c(\"time\",\"conc\"), id=\"Subject\", time=\"time\", lagfirst = NA) head(data) #>   Subject  Wt Apgar ApgarInd  time dose conc event id time.lag conc.lag #> 1      42 2.8     9     >= 5  14.0   NA 13.3     1  1       NA       NA #> 2      42 2.8     9     >= 5  95.5   NA 13.9     1  1     14.0     13.3 #> 3      28 3.2     9     >= 5   2.0   NA 16.9     1  2       NA       NA #> 4      30 1.8     8     >= 5   6.3   NA 17.9     1  3       NA       NA #> 5      30 1.8     8     >= 5 226.3   NA 16.5     1  3      6.3     17.9 #> 6      56 0.6     4      < 5  20.0   NA 18.8     1  4       NA       NA  mph <- coxph(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) + I(conc.lag>20 & conc.lag<=30)  + I(conc.lag>30)+ cluster(id),,data=data) summary(mph) #> Call: #> coxph(formula = Surv(time.lag, time, event) ~ I(conc.lag > 0 &  #>     conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) + I(conc.lag >  #>     30), data = data, cluster = id) #>  #>   n= 95, number of events= 95  #>    (59 observations deleted due to missingness) #>  #>                                         coef exp(coef) se(coef) robust se     z #> I(conc.lag > 0 & conc.lag <= 20)TRUE  0.6546    1.9243   0.3566    0.2914 2.246 #> I(conc.lag > 20 & conc.lag <= 30)TRUE 0.3741    1.4537   0.3142    0.2621 1.427 #> I(conc.lag > 30)TRUE                      NA        NA   0.0000    0.0000    NA #>                                       Pr(>|z|)   #> I(conc.lag > 0 & conc.lag <= 20)TRUE    0.0247 * #> I(conc.lag > 20 & conc.lag <= 30)TRUE   0.1535   #> I(conc.lag > 30)TRUE                        NA   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                                       exp(coef) exp(-coef) lower .95 upper .95 #> I(conc.lag > 0 & conc.lag <= 20)TRUE      1.924     0.5197    1.0870     3.406 #> I(conc.lag > 20 & conc.lag <= 30)TRUE     1.454     0.6879    0.8697     2.430 #> I(conc.lag > 30)TRUE                         NA         NA        NA        NA #>  #> Concordance= 0.544  (se = 0.023 ) #> Likelihood ratio test= 3.53  on 2 df,   p=0.2 #> Wald test            = 5.19  on 2 df,   p=0.07 #> Score (logrank) test = 3.49  on 2 df,   p=0.2,   Robust = 6.28  p=0.04 #>  #>   (Note: the likelihood ratio and score tests assume independence of #>      observations within a cluster, the Wald and robust score tests do not). data$weight <- iiw(mph,data,\"id\",\"time\",TRUE) head(data) #>   Subject  Wt Apgar ApgarInd  time dose conc event id time.lag conc.lag #> 1      42 2.8     9     >= 5  14.0   NA 13.3     1  1       NA       NA #> 2      42 2.8     9     >= 5  95.5   NA 13.9     1  1     14.0     13.3 #> 3      28 3.2     9     >= 5   2.0   NA 16.9     1  2       NA       NA #> 4      30 1.8     8     >= 5   6.3   NA 17.9     1  3       NA       NA #> 5      30 1.8     8     >= 5 226.3   NA 16.5     1  3      6.3     17.9 #> 6      56 0.6     4      < 5  20.0   NA 18.8     1  4       NA       NA #>      weight #> 1 1.0000000 #> 2 0.5196749 #> 3 1.0000000 #> 4 1.0000000 #> 5 0.5196749 #> 6 1.0000000"},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute inverse-intensity weights. — iiw.weights","title":"Compute inverse-intensity weights. — iiw.weights","text":"Since vector weights ordered id time, intend merge weights onto original dataset highly recommended sort data running iiw.weights","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute inverse-intensity weights. — iiw.weights","text":"","code":"iiw.weights(   formulaph,   formulanull = NULL,   data,   id,   time,   event,   lagvars,   invariant = NULL,   maxfu,   lagfirst = lagfirst,   first )"},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute inverse-intensity weights. — iiw.weights","text":"formulaph formula proportional hazards model visit intensity used derive inverse-intensity weights. formula usually use counting process format (.e. Surv(start,stop,event)). frailty model used, cluster(id) term appear covariates formulanull stabilised weights used, formula null model used stabilise weights data data frame containing variables model id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred event character string indicating column data indicates whether visit occurred. every row corresponds visit, column consist entirely ones lagvars vector variable names corresponding variables need lagged one visit fit visit intensity model. Typically time one variables. function internally add columns data containing values lagged variables previous visit. Values lagged variables subject's first visit set NA. access variables specifying proportional hazards formulae, add \".lag\" variable wish lag. example, time variable time, time.lag time previous visit invariant vector variable names corresponding variables data time-invariant. necessary list every variable, just invariant also included proportional hazards model maxfu maximum follow-time(s). everyone followed length time, can given single value. individuals different follow-times, maxfu number elements rows data lagfirst vector giving value lagged variable first time within subject. helpful , example, time variable lagged know subjects entered study time zero first logical variable. TRUE, first observation individual assigned intensity 1. appropriate first visit baseline visit recruitment study occurred; case baseline visit observed probability 1.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute inverse-intensity weights. — iiw.weights","text":"vector inverse-intensity weights, ordered id time","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute inverse-intensity weights. — iiw.weights","text":"Given longitudinal data irregular visit times, fit Cox proportional hazards model visit intensity, use compute inverse-intensity weights","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute inverse-intensity weights. — iiw.weights","text":"Lin H, Scharfstein , Rosenheck RA. Analysis Longitudinal data Irregular, Informative Follow-. Journal Royal Statistical Society, Series B (2004), 66:791-813 Buzkova P, Lumley T. Longitudinal data analysis generalized linear models follow-dependent outcome-related variables. Canadian Journal Statistics 2007; 35:485-500.","code":""},{"path":[]},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiw.weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute inverse-intensity weights. — iiw.weights","text":"","code":"library(nlme) data(Phenobarb) library(survival) library(geepack) library(data.table) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) data <- data[data$time<16*24,] i <- iiw.weights(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) + I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+ cluster(id), id=\"id\",time=\"time\",event=\"event\",data=data, invariant=\"id\",lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=0,first=TRUE) data$weight <- i$iiw.weight summary(i$m) #> Call: #> coxph(formula = Surv(time.lag, time, event) ~ I(conc.lag > 0 &  #>     conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) + I(conc.lag >  #>     30), data = datacox, cluster = id) #>  #>   n= 154, number of events= 95  #>    (59 observations deleted due to missingness) #>  #>                                         coef exp(coef) se(coef) robust se     z #> I(conc.lag > 0 & conc.lag <= 20)TRUE  0.7379    2.0915   0.3398    0.3066 2.406 #> I(conc.lag > 20 & conc.lag <= 30)TRUE 0.3261    1.3856   0.3004    0.2851 1.144 #> I(conc.lag > 30)TRUE                      NA        NA   0.0000    0.0000    NA #>                                       Pr(>|z|)   #> I(conc.lag > 0 & conc.lag <= 20)TRUE    0.0161 * #> I(conc.lag > 20 & conc.lag <= 30)TRUE   0.2527   #> I(conc.lag > 30)TRUE                        NA   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                                       exp(coef) exp(-coef) lower .95 upper .95 #> I(conc.lag > 0 & conc.lag <= 20)TRUE      2.091     0.4781    1.1467     3.815 #> I(conc.lag > 20 & conc.lag <= 30)TRUE     1.386     0.7217    0.7924     2.423 #> I(conc.lag > 30)TRUE                         NA         NA        NA        NA #>  #> Concordance= 0.559  (se = 0.022 ) #> Likelihood ratio test= 5.12  on 2 df,   p=0.08 #> Wald test            = 6.69  on 2 df,   p=0.04 #> Score (logrank) test = 5.31  on 2 df,   p=0.07,   Robust = 7.18  p=0.03 #>  #>   (Note: the likelihood ratio and score tests assume independence of #>      observations within a cluster, the Wald and robust score tests do not). # can use to fit a weighted GEE mw <- geeglm(conc ~ I(time^3) + log(time) , id=Subject, data=data, weights=weight) summary(mw) #>  #> Call: #> geeglm(formula = conc ~ I(time^3) + log(time), data = data, weights = weight,  #>     id = Subject) #>  #>  Coefficients: #>               Estimate    Std.err   Wald Pr(>|W|)     #> (Intercept)  1.684e+01  1.049e+00 257.82   <2e-16 *** #> I(time^3)   -6.410e-07  6.112e-08 109.99   <2e-16 *** #> log(time)    3.064e+00  3.588e-01  72.89   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Correlation structure = independence  #> Estimated Scale Parameters: #>  #>             Estimate Std.err #> (Intercept)    47.31   14.66 #> Number of clusters:   59  Maximum cluster size: 6  # agrees with results through the single command iiwgee miiwgee <- iiwgee(conc ~ I(time^3) + log(time), Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) + I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+ cluster(id), id=\"id\",time=\"time\",event=\"event\",data=data, invariant=\"id\",lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=0,first=TRUE) summary(miiwgee$geefit) #>  #> Call: #> geeglm(formula = formulagee, family = family, data = data, weights = useweight,  #>     id = iddup, corstr = \"independence\") #>  #>  Coefficients: #>              Estimate   Std.err  Wald Pr(>|W|)     #> (Intercept)  1.65e+01  1.02e+00 262.0   <2e-16 *** #> I(time^3)   -6.63e-07  7.65e-08  75.2   <2e-16 *** #> log(time)    3.25e+00  4.05e-01  64.4    1e-15 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Correlation structure = independence  #> Estimated Scale Parameters: #>  #>             Estimate Std.err #> (Intercept)     49.1      17 #> Number of clusters:   59  Maximum cluster size: 6"},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an inverse-intensity weighted GEE. — iiwgee","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"Implements inverse-intensity weighted GEEs first described Lin, Scharfstein Rosenheck (2004). Cox proportional hazards model applied visit intensities, hazard multipliers used compute inverse-intensity weights. Using approach described Buzkova Lumley (2007) avoids need compute baseline hazard.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"","code":"iiwgee(   formulagee,   formulaph,   formulanull = NULL,   data,   id,   time,   event,   family = gaussian,   lagvars,   invariant = NULL,   maxfu,   lagfirst,   first )"},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"formulagee formula GEE model fit. syntax used geeglm formulaph formula proportional hazards model visit intensity used derive inverse-intensity weights. formula usually use counting process format (.e. Surv(start,stop,event)) formulanull stabilised weights used, formula null model used stabilise weights data data frame containing variables model id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred event character string indicating column data indicates whether visit occurred. every row corresponds visit, column consist entirely ones family family used GEE fit. See geeglm documentation lagvars vector variable names corresponding variables need lagged one visit fit visit intensity model. Typically time one variables. function internally add columns data containing values lagged variables previous visit. Values lagged variables subject's first visit set NA. access variables specifying proportional hazards formulae, add \".lag\" variable wish lag. example, time variable time, time.lag time previous visit invariant vector variable names corresponding variables data time-invariant. necessary list every variable, just invariant also included proportional hazards model maxfu maximum follow-time(s). everyone followed length time, can given single value. individuals different follow-times, maxfu number elements rows data lagfirst vector giving value lagged variable first time within subject. helpful , example, time variable lagged know subjects entered study time zero first logical variable. TRUE, first observation individual assigned intensity 1. appropriate first visit baseline visit recruitment study occurred; case baseline visit observed probability 1.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"list, following elements: geefit fitted GEE, see documentation geeglm details phfit fitted proportional hazards model, see documentation coxph details","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"Let outcome interest \\(Y\\) suppose subject \\(j^{th}\\) observation \\(T_{ij}\\). Let \\(N_i(t)\\) counting process number observations subject including time t. Suppose \\(N_i\\) intensity \\(\\lambda\\) given $$\\lambda_i(t)=\\lambda0(t)exp(Z_i(t)\\gamma).$$ inverse-intensity weights $$exp(-Z_i(t)\\gamma).$$ \\(Y_i\\) vector observations subject \\(\\), regressed onto \\(X_i\\) (.e. \\(E(Y_i|X_i)=\\mu(X_i;\\beta)\\) \\(g(\\mu(X_i;beta)=X_i\\beta\\), inverse-intensity weighted GEE equations $$\\sum_i \\frac{\\partial\\mu_i}{\\partial\\beta}V_i^{-1}\\Delta_i(Y_i X_i\\beta)=0$$, \\(\\Delta_i\\) diagonal matrix \\(j^{th}\\) entry equal \\(\\exp(-Z_i(T_{ij})\\gamma)\\) $V_i$ working variance matrix. Warning: Due way gee functions incorporate weights, using inverse-intensity weighting use working independence.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"Lin H, Scharfstein , Rosenheck RA. Analysis Longitudinal data Irregular, Informative Follow-. Journal Royal Statistical Society, Series B (2004), 66:791-813 Buzkova P, Lumley T. Longitudinal data analysis generalized linear models follow-dependent outcome-related variables. Canadian Journal Statistics 2007; 35:485-500.","code":""},{"path":[]},{"path":"https://epullenayegum.github.io/IrregLong/reference/iiwgee.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit an inverse-intensity weighted GEE. — iiwgee","text":"","code":"library(nlme) data(Phenobarb) library(survival) library(geepack) library(data.table) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) data <- data[data$time<16*24,] miiwgee <- iiwgee(conc ~ I(time^3) + log(time), Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) + I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+ cluster(id), id=\"id\",time=\"time\",event=\"event\",data=data, invariant=\"id\",lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=0,first=TRUE) summary(miiwgee$geefit) #>  #> Call: #> geeglm(formula = formulagee, family = family, data = data, weights = useweight,  #>     id = iddup, corstr = \"independence\") #>  #>  Coefficients: #>              Estimate   Std.err  Wald Pr(>|W|)     #> (Intercept)  1.65e+01  1.02e+00 262.0   <2e-16 *** #> I(time^3)   -6.63e-07  7.65e-08  75.2   <2e-16 *** #> log(time)    3.25e+00  4.05e-01  64.4    1e-15 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Correlation structure = independence  #> Estimated Scale Parameters: #>  #>             Estimate Std.err #> (Intercept)     49.1      17 #> Number of clusters:   59  Maximum cluster size: 6  summary(miiwgee$phfit) #> Call: #> coxph(formula = Surv(time.lag, time, event) ~ I(conc.lag > 0 &  #>     conc.lag <= 20) + I(conc.lag > 20 & conc.lag <= 30) + I(conc.lag >  #>     30), data = datacox, cluster = id) #>  #>   n= 154, number of events= 95  #>    (59 observations deleted due to missingness) #>  #>                                        coef exp(coef) se(coef) robust se    z #> I(conc.lag > 0 & conc.lag <= 20)TRUE  0.738     2.091    0.340     0.307 2.41 #> I(conc.lag > 20 & conc.lag <= 30)TRUE 0.326     1.386    0.300     0.285 1.14 #> I(conc.lag > 30)TRUE                     NA        NA    0.000     0.000   NA #>                                       Pr(>|z|)   #> I(conc.lag > 0 & conc.lag <= 20)TRUE     0.016 * #> I(conc.lag > 20 & conc.lag <= 30)TRUE    0.253   #> I(conc.lag > 30)TRUE                        NA   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                                       exp(coef) exp(-coef) lower .95 upper .95 #> I(conc.lag > 0 & conc.lag <= 20)TRUE       2.09      0.478     1.147      3.81 #> I(conc.lag > 20 & conc.lag <= 30)TRUE      1.39      0.722     0.792      2.42 #> I(conc.lag > 30)TRUE                         NA         NA        NA        NA #>  #> Concordance= 0.559  (se = 0.022 ) #> Likelihood ratio test= 5.12  on 2 df,   p=0.08 #> Wald test            = 6.69  on 2 df,   p=0.04 #> Score (logrank) test = 5.31  on 2 df,   p=0.07,   Robust = 7.18  p=0.03 #>  #>   (Note: the likelihood ratio and score tests assume independence of #>      observations within a cluster, the Wald and robust score tests do not).  # compare to results without weighting m <- geeglm(conc ~ I(time^3) + log(time) , id=Subject, data=data); print(summary(m)) #>  #> Call: #> geeglm(formula = conc ~ I(time^3) + log(time), data = data, id = Subject) #>  #>  Coefficients: #>              Estimate   Std.err  Wald Pr(>|W|)     #> (Intercept)  1.66e+01  9.91e-01 280.1   <2e-16 *** #> I(time^3)   -6.47e-07  7.00e-08  85.4   <2e-16 *** #> log(time)    3.11e+00  3.49e-01  79.3   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Correlation structure = independence  #> Estimated Scale Parameters: #>  #>             Estimate Std.err #> (Intercept)     46.9    14.5 #> Number of clusters:   59  Maximum cluster size: 6  time <- (1:200) unweighted <- cbind(rep(1,200),time^3,log(time))%*%m$coefficients weighted <- cbind(rep(1,200),time^3,log(time))%*%miiwgee$geefit$coefficients plot(data$time,data$conc,xlim=c(0,200),pch=16) lines(time,unweighted,type=\"l\") lines(time,weighted,col=2) legend (0,60,legend=c(\"Unweighted\",\"Inverse-intensity weighted\"),col=1:2,bty=\"n\",lty=1)"},{"path":"https://epullenayegum.github.io/IrregLong/reference/lagfn.html","id":null,"dir":"Reference","previous_headings":"","what":"Create lagged versions the variables in data — lagfn","title":"Create lagged versions the variables in data — lagfn","text":"Create lagged versions variables data","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/lagfn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create lagged versions the variables in data — lagfn","text":"","code":"lagfn(data, lagvars, id, time, lagfirst = NA)"},{"path":"https://epullenayegum.github.io/IrregLong/reference/lagfn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create lagged versions the variables in data — lagfn","text":"data data lagged lagvars names columns data lagged id character indicating column data contains subject identifiers. ids assumed consecutive integers, first subject id 1 time character indicating column data contains times observations data made lagfirst vector giving value lagged variable first time within subject. helpful , example, time variable lagged know subjects entered study time zero","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/lagfn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create lagged versions the variables in data — lagfn","text":"original data frame lagged variables added columns. example, data frame contains variable named x giving value x subject visit j, returned data frame contain column named x.lag containing value x subject visit j-1. j first visit subject , lagged value set NA","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/lagfn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create lagged versions the variables in data — lagfn","text":"","code":"library(nlme) library(data.table) data(Phenobarb) head(Phenobarb) #> Grouped Data: conc ~ time | Subject #>   Subject  Wt Apgar ApgarInd time dose conc #> 1       1 1.4     7     >= 5  0.0 25.0   NA #> 2       1 1.4     7     >= 5  2.0   NA 17.3 #> 3       1 1.4     7     >= 5 12.5  3.5   NA #> 4       1 1.4     7     >= 5 24.5  3.5   NA #> 5       1 1.4     7     >= 5 37.0  3.5   NA #> 6       1 1.4     7     >= 5 48.0  3.5   NA  data <- lagfn(Phenobarb,\"time\",\"Subject\",\"time\") head(data) #>   Subject  Wt Apgar ApgarInd time dose conc time.lag #> 1      42 2.8     9     >= 5  0.0   28   NA       NA #> 2      42 2.8     9     >= 5 12.0   28   NA      0.0 #> 3      42 2.8     9     >= 5 14.0   NA 13.3     12.0 #> 4      42 2.8     9     >= 5 23.7    7   NA     14.0 #> 5      42 2.8     9     >= 5 36.2    7   NA     23.7 #> 6      42 2.8     9     >= 5 47.8    7   NA     36.2"},{"path":"https://epullenayegum.github.io/IrregLong/reference/mo.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple outputation for longitudinal data subject to irregular observation. — mo","title":"Multiple outputation for longitudinal data subject to irregular observation. — mo","text":"Multiple outputation procedure whereby excess observations repeatedly randomly sampled discarded. method originally developed handle clustered data cluster size informative, example studying pups litter. case, analysis ignores cluster size results larger litters -represented marginal analysis. Multiple outputation circumvents problem randomly selecting one observation per cluster. Multiple outputation adapted handle longitudinal data subject irregular observation; probability retained given outputation inversely proportional visit intensity. function creates multiply outputted datasets, analyses separately, combines results produce single estimate.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/mo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple outputation for longitudinal data subject to irregular observation. — mo","text":"","code":"mo(   noutput,   fn,   data,   weights,   singleobs,   id,   time,   keep.first,   var = TRUE,   ... )"},{"path":"https://epullenayegum.github.io/IrregLong/reference/mo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple outputation for longitudinal data subject to irregular observation. — mo","text":"noutput number outputations used fn function applied outputted datasets. fn return vector scalar; var=TRUE second column fn estimate standard error. data original dataset multiple outputation performed weights weights used outputation, .e. inverse probability given observation selected creating outputted dataset. Ignored singleobs=TRUE singleobs logical variable indicating whether single observation retained subject id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred keep.first logical variable indicating whether first observation retained probability 1. useful data consists observation baseline followed follow-stochastic time points. var logical variable indicating whether fn returns variances addition point estimates ... arguments fn.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/mo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple outputation for longitudinal data subject to irregular observation. — mo","text":"list containing multiple outputation estimate function fn applied data, standard error, relative efficiency using noutput outputations opposed infinite number","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/mo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiple outputation for longitudinal data subject to irregular observation. — mo","text":"Hoffman E, Sen P, Weinberg C. Within-cluster resampling. Biometrika 2001; 88:1121-1134 Follmann D, Proschan M, Leifer E. Multiple outputation: inference complex clustered data averaging analyses independent data. Biometrics 2003; 59:420-429 Pullenayegum EM. Multiple outputation analysis longitudinal data subject irregular observation. Statistics Medicine (press) .","code":""},{"path":[]},{"path":"https://epullenayegum.github.io/IrregLong/reference/mo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple outputation for longitudinal data subject to irregular observation. — mo","text":"","code":"library(nlme) data(Phenobarb) library(survival) library(geepack) library(data.table)  Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) data <- data[data$time<16*24,] i <- iiw.weights(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) + I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+ cluster(id), id=\"id\",time=\"time\",event=\"event\",data=data, invariant=\"id\",lagvars=c(\"time\",\"conc\"),maxfu=16*24,          lagfirst=c(0,0),first=TRUE) wt <- i$iiw.weight wt[wt>quantile(i$iiw.weight,0.95)] <- quantile(i$iiw.weight,0.95) data$wt <- wt reg <- function(data){ est <- summary(geeglm(conc~I(time^3) + log(time), id=id,data=data))$coefficients[,1:2] est <- data.matrix(est) return(est) }  mo(20,reg,data,wt,singleobs=FALSE,id=\"id\",time=\"time\",keep.first=FALSE) #> $est #> [1]  1.66e+01 -6.63e-07  3.12e+00 #>  #> $se #> [1] 1.028997 0.000326 0.661138 #>  #> $RE.MO #> [1] 1.02 1.00 1.01 #>  # On outputation, the dataset contains small numbers of observations per subject # and hence the GEE sandwich variance estimate underestimates variance; this is why # the outputation-based variance estimate fails. This can be remedied by using a # sandwich variance error correction (e.g. Fay-Graubard, Mancl-DeRouen)."},{"path":"https://epullenayegum.github.io/IrregLong/reference/outputation.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an outputted dataset for use with multiple outputation. — outputation","title":"Create an outputted dataset for use with multiple outputation. — outputation","text":"Multiple outputation procedure whereby excess observations repeatedly randomly sampled discarded. method originally developed handle clustered data cluster size informative, example studying pups litter. case, analysis ignores cluster size results larger litters -represented marginal analysis. Multiple outputation circumvents problem randomly selecting one observation per cluster. Multiple outputation adapted handle longitudinal data subject irregular observation; probability retained given outputation inversely proportional visit intensity. function creates single outputted dataset.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/outputation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an outputted dataset for use with multiple outputation. — outputation","text":"","code":"outputation(data, weights, singleobs, id, time, keep.first)"},{"path":"https://epullenayegum.github.io/IrregLong/reference/outputation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an outputted dataset for use with multiple outputation. — outputation","text":"data original dataset multiple outputation performed weights weights used outputation, .e. inverse probability given observation selected creating outputted dataset. Ignored singleobs=TRUE singleobs logical variable indicating whether single observation retained subject id character string indicating column data identifies subjects time character string indicating column data contains time visit occurred keep.first logical variable indicating whether first observation retained probability 1. useful data consists observation baseline followed follow-stochastic time points.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/outputation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an outputted dataset for use with multiple outputation. — outputation","text":"outputted dataset.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/reference/outputation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create an outputted dataset for use with multiple outputation. — outputation","text":"Hoffman E, Sen P, Weinberg C. Within-cluster resampling. Biometrika 2001; 88:1121-1134 Follmann D, Proschan M, Leifer E. Multiple outputation: inference complex clustered data averaging analyses independent data. Biometrics 2003; 59:420-429 Pullenayegum EM. Multiple outputation analysis longitudinal data subject irregular observation. Statistics Medicine (press).","code":""},{"path":[]},{"path":"https://epullenayegum.github.io/IrregLong/reference/outputation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an outputted dataset for use with multiple outputation. — outputation","text":"","code":"library(nlme) data(Phenobarb) library(survival) library(geepack) library(data.table) Phenobarb$event <- 1-as.numeric(is.na(Phenobarb$conc)) data <- Phenobarb data <- data[data$event==1,] data$id <- as.numeric(data$Subject) data <- data[data$time<16*24,] i <- iiw.weights(Surv(time.lag,time,event)~I(conc.lag>0 & conc.lag<=20) + I(conc.lag>20 & conc.lag<=30) + I(conc.lag>30)+ cluster(id), id=\"id\",time=\"time\",event=\"event\",data=data, invariant=\"id\",lagvars=c(\"time\",\"conc\"),maxfu=16*24,lagfirst=0,first=TRUE) data$weight <- i$iiw.weight head(data) #> Grouped Data: conc ~ time | Subject #>    Subject  Wt Apgar ApgarInd  time dose conc event id weight #> 2        1 1.4     7     >= 5   2.0   NA 17.3     1 32  1.000 #> 12       1 1.4     7     >= 5 112.5   NA 31.0     1 32  0.478 #> 14       2 1.5     9     >= 5   2.0   NA  9.7     1 38  1.000 #> 20       2 1.5     9     >= 5  63.5   NA 24.6     1 38  1.000 #> 27       2 1.5     9     >= 5 135.5   NA 33.0     1 38  0.478 #> 29       3 1.5     6     >= 5   1.5   NA 18.0     1 11  1.000 data.output1 <-   outputation(data,data$weight,singleobs=FALSE, id=\"id\",time=\"time\",keep.first=FALSE) head(data.output1) #> Grouped Data: conc ~ time | Subject #>    Subject  Wt Apgar ApgarInd  time dose conc event id weight #> 2        1 1.4     7     >= 5   2.0   NA 17.3     1 32  1.000 #> 12       1 1.4     7     >= 5 112.5   NA 31.0     1 32  0.478 #> 14       2 1.5     9     >= 5   2.0   NA  9.7     1 38  1.000 #> 20       2 1.5     9     >= 5  63.5   NA 24.6     1 38  1.000 #> 27       2 1.5     9     >= 5 135.5   NA 33.0     1 38  0.478 #> 29       3 1.5     6     >= 5   1.5   NA 18.0     1 11  1.000 data.output2 <-   outputation(data,data$weight,singleobs=FALSE, id=\"id\",time=\"time\",keep.first=FALSE) head(data.output2) #> Grouped Data: conc ~ time | Subject #>    Subject  Wt Apgar ApgarInd  time dose conc event id weight #> 2        1 1.4     7     >= 5   2.0   NA 17.3     1 32      1 #> 14       2 1.5     9     >= 5   2.0   NA  9.7     1 38      1 #> 20       2 1.5     9     >= 5  63.5   NA 24.6     1 38      1 #> 29       3 1.5     6     >= 5   1.5   NA 18.0     1 11      1 #> 36       3 1.5     6     >= 5  83.5   NA 23.8     1 11      1 #> 42       3 1.5     6     >= 5 134.3   NA 24.3     1 11      1 data.output3 <-   outputation(data,data$weight,singleobs=FALSE, id=\"id\",time=\"time\",keep.first=FALSE) head(data.output3) #> Grouped Data: conc ~ time | Subject #>    Subject  Wt Apgar ApgarInd  time dose conc event id weight #> 2        1 1.4     7     >= 5   2.0   NA 17.3     1 32  1.000 #> 12       1 1.4     7     >= 5 112.5   NA 31.0     1 32  0.478 #> 14       2 1.5     9     >= 5   2.0   NA  9.7     1 38  1.000 #> 20       2 1.5     9     >= 5  63.5   NA 24.6     1 38  1.000 #> 29       3 1.5     6     >= 5   1.5   NA 18.0     1 11  1.000 #> 36       3 1.5     6     >= 5  83.5   NA 23.8     1 11  1.000 # Note that the outputted dataset varies with each command run; outputation is done at random"},{"path":[]},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"minor-changes-0-3-4","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"IrregLong 0.3.4","text":"Added error message extent..irregularity formula /ncutpts specified absence scheduled visit times made use data.table package lagging variables adding censored rows","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"bug-fixes-0-3-4","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"IrregLong 0.3.4","text":"extent..irregularity previously allowed time variable called “time”; now fixed","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"irreglong-033","dir":"Changelog","previous_headings":"","what":"IrregLong 0.3.3","title":"IrregLong 0.3.3","text":"CRAN release: 2020-08-24","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"minor-changes-0-3-3","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"IrregLong 0.3.3","text":"due archival frailtypack package, frailty models now estimated using coxph rather frailtyPenal","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"irreglong-032","dir":"Changelog","previous_headings":"","what":"IrregLong 0.3.2","title":"IrregLong 0.3.2","text":"CRAN release: 2020-06-24","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"bug-fixes-0-3-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"IrregLong 0.3.2","text":"iiw.weights failed consider interval last observed visit end follow-time maxfu supplied single number. fixed.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"irreglong-031","dir":"Changelog","previous_headings":"","what":"IrregLong 0.3.1","title":"IrregLong 0.3.1","text":"CRAN release: 2020-05-23","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"bug-fixes-0-3-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"IrregLong 0.3.1","text":"Fixed coding error led extent..irregularity fail scheduledtimes provided.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"irreglong-030","dir":"Changelog","previous_headings":"","what":"IrregLong 0.3.0","title":"IrregLong 0.3.0","text":"CRAN release: 2020-05-01","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"major-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"IrregLong 0.3.0","text":"Added function (extent..irregularity) provide graphical numeric summaries extent irregularity.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"minor-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"IrregLong 0.3.0","text":"Added option Liang function provide argument function computing value covariates X subject given time t, just observation times.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"irreglong-020","dir":"Changelog","previous_headings":"","what":"IrregLong 0.2.0","title":"IrregLong 0.2.0","text":"CRAN release: 2020-01-24","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"major-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"IrregLong 0.2.0","text":"using lagged variable, option include value first lagged observation within subject. function (abacus.plot) producing abacus plot added. Liang model now allows time-invariant covariates included visit process model.","code":""},{"path":"https://epullenayegum.github.io/IrregLong/news/index.html","id":"bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"IrregLong 0.2.0","text":"documentation (examples vignette) updated use dosing weight measurement frequency model. tinvarcols can omitted addcensoredrows, iiwgee, iiw.weights maxfu=NULL. lagfn addcensoredrows longer require subject identifiers numeric.","code":""}]
